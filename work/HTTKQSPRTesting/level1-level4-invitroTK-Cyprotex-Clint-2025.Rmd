---
title: "Evaluation of Machine Learning-Based NAM Models for Key HTTK Parameters in Toxicokinetics"
author: "Tabatabaei Sadeghi S, Guider C, Davidson-Fritz S, Dinallo R, Li L, Strock C , Wambaugh JF"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{h) Dawson's Model Evaluation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
*Please send questions to tabatabaeisadeghi.sahar@epa.gov*
  

"Evaluation of Dawson's Model for predicting Intrinsic Hepatic Clearance (Clint)" 

Tabatabaei Sadeghi S, Guider C, Davidson-Fritz S, Dinallo R, Li L, Strock C , Wambaugh JF
  
##Abstract

Background and purpose:
High-throughput toxicokinetic (HTTK) modeling is essential for assessing risks posed by chemical exposure, especially in regulatory and environmental contexts. HTTK uses chemical-specific in vitro toxicokinetic data to provide in vitro-in vivo extrapolation (IVIVE). IVIVE allows integration of data from toxicological new approach methods (NAMs) into human health risk estimates. However, HTTK measurements are slower than toxicological NAMs  , creating a lag between the availability of toxicological NAM data and the data necessary for IVIVE. Alternatively, quantitative structure-property relationship models (QSPRs) have been developed to predict HTTK values for chemicals that have not yet had measurements. In this study, we evaluate existing predictive models for key toxicokinetic parameters: Caco-2 permeability, fraction unbound in plasma (fup), and intrinsic hepatic clearance rate (Clint). We use newly measured HTTK data to evaluate the accuracy of QSPRs. Chemical classes where QSPRs are accurate may not need to be measured in the future.
Methods:
We focused on evaluating QSPR models developed to cover non-pharmaceutical compounds. These models were typically trained on a mix of both pharmaceuticals (where there are larger quantities of data) and non-pharmaceuticals (whose physico-chemical properties may vary from the pharmaceutical space). The chemical datasets used for evaluating these models were generated by Cyprotex, with the distinct sets employed for each assay (Caco-2 permeability, fup, and Clint) to allow for specific assessments. Data were analyzed with prototype R package “invitroTKstats”. The first QSPR model assessed was a Caco-2 permeability model for predicting intestinal absorption. We compared versions of that model that made categorical predictions (low/medium/high permeability) with a continuous model to examine whether emphasizing the outlier classes (low permeability) increased sensitivity for detecting outliers. We also examined QSPRs recently developed to predict (fup) and Clint. Each model was evaluated for accuracy, robustness, and applicability in high-throughput settings by comparing their predictions with in vivo observations, focusing on implications for in vitro-to-in vivo extrapolation (IVIVE). 
Results:
Of the 127 chemicals initially assessed, 113 yielded successful Caco-2 permeability measurements, while 14 failed due to missing data or errors in measurement. Fraction recovery (Frec), applied as a mass balance metric to quantify the proportion of the initial compound recovered at the conclusion of the experiment, indicated that 57 of the 113 chemicals met the acceptable recovery range criteria (0.2–4.0).
The domain of applicability (DoA), which defines the chemical space within which model predictions are considered reliable, identified that 50 of these 57 chemicals fell within the estimated DoA, based on the criteria set by Roy et al. (2015). Ultimately, a subset of 57 chemicals was evaluated for Caco-2 permeability under these established criteria:
A QSPR Random Forest model was available to predict Caco-2 permeability, utilizing both regression and classification approaches. For the regression model on the training set, two key metrics—Root Mean Square Error (RMSE) and R-squared (R²)—were evaluated, with results of 0.56 and 0.57, respectively. These values suggest moderate predictive accuracy. For the classification model accuracy— a key metric for classification—was measured at 0.69 on the training set, showing a reasonable initial classification performance. Upon evaluation with the test set, both models achieved an accuracy of 0.77. However, Kappa values were low, with 0.12 for the classification model and 0 for the regression model, indicating poor alignment between predicted and actual values on unseen data. These findings suggest that while the models demonstrate moderate performance on the training set, their predictive reliability diminishes on the test set, emphasizing the need for further refinement to enhance their agreement with experimental results and improve their applicability in predicting Caco-2 permeability.
Class 1 ("slow absorption?") chemicals were not predicted correctly by the Caco-2 QSPR models. When predicting high absorption (class 3) for chemicals that are actually low absorption (class 1), the error is health-protective, as it underestimates the required dose. However, the reverse error—predicting class 1 when the chemical is actually class 3—poses a higher risk, as it may lead to overestimating the amount of chemical needed for absorption. No incidences of underestimating risk occurred for Caco-2. 
Conclusions:
This comparison sheds light on the effectiveness of HTTK QSPR models for broader application in chemical risk prioritization. To date we have focused on Caco-2 QSPRs, but the approach generalizes to plasma protein binding and intrinsic hepatic clearance. Where the QSPRs are found to be adequate (low RMSE, sensitive to outliers) they may be a sufficient alternative to HTTK? measurement. When the QSPRs seem inadequate, new QSPRs must be built using a combination of more advanced techniques and new data.
The views expressed in this abstract are those of the authors and do not necessarily reflect the views or policies of the U.S. EPA.


##invitroTKstats Version

This vignette was created with **invtiroTKstats** v0.0.11


## Prepare for session
R package **knitr** generates html and PDF documents from this RMarkdown file,
Each bit of code that follows is known as a "chunk". We start by telling 
**knitr** how we want our chunks to look.
```{r configure_knitr, eval = TRUE}
knitr::opts_chunk$set(collapse = TRUE, comment = '#>')
options(rmarkdown.html_vignette.check_title = FALSE)
```

### Clear the memory
It is a bad idea to let variables and other information from previous R
sessions float around, so we first remove everything in the R memory.
```{r clear_memory, eval = TRUE}
rm(list=ls()) 
```

### eval = execute.vignette
If you are using the RMarkdown version of this vignette (extension, .RMD) you
will be able to see that several chunks of code in this vignette
have the statement "eval = execute.vignette". The next chunk of code, by default,
sets execute.vignette = FALSE.  This means that the code is included (and necessary) but was
not run when the vignette was built. We do this because some steps require 
extensive computing time and the checks on CRAN limit how long we can spend
building the package. If you want this vignette to work, you must run all code,
either by cutting and pasting it into R. Or, if viewing the .RMD file, you can
either change execute.vignette to TRUE or press "play" (the green arrow) on
each chunk in RStudio.
```{r runchunks, eval = TRUE}
# Set whether or not the following chunks will be executed (run):
execute.vignette <- FALSE
```

### Load the relevant libraries

We use the command 'library()' to load various R packages for our analysis.
If you get the message "Error in library(X) : there is no package called 'X'"
then you will need to install that package: 

From the R command prompt:

install.packages("X")

Or, if using RStudio, look for 'Install Packages' under 'Tools' tab.


# Here's the new R package for analyzing these data:
```{r load_packages, eval = TRUE}  
library(invitroTKstats)

# There are multiple packages for loading Excel files, but I've been using this
# one lately:
library(readxl)
```

# Clear memory:
```{r clear_memory, eval = TRUE}     
rm(list=ls())
```


```{r set_working_directory, eval = TRUE}   

setwd("C:/Users/stabatab/OneDrive - Environmental Protection Agency (EPA)/Profile/Desktop/ExpoCast_Projec/Project_Pred_Caco2_Clint_Fup/invitroTKstats/CyprotexTO1//out_clint")


``` 
# Describe chemical tested:
```{r test_Chemicals, eval=TRUE}
chem.ids <- data.frame(read_excel("162Clint_Com_ChemID_DTXSID.xlsx"))
SM62=data.frame(read_excel("Unique162_Clint_SMILES.xlsx"))
SM60=data.frame(read_excel("Unique160_Clint_SMILES.xlsx"))
miss=setdiff(SM62$DTXSID,SM60$DTXSID)

chem.ids$Chem.Lab.ID=trimws(chem.ids$Chem.Lab.ID)
value=trimws("DTXSID9026926")

chem.ids$Chem.Lab.ID=as.character(chem.ids$Chem.Lab.ID)
```
# Load mass-spectrometry data:
```{r load_data, eval=TRUE}
data.guide <- data.frame(read_excel("dataguide_clint_11.24.xlsx"))

dc.hep1 <- merge_level0(level0.catalog= data.guide,
                         chem.ids = chem.ids,
                         file.col = "File",
                         sheet.col = "Sheet",
                         skip.rows.col = "Skip.Rows",
                         date.col = "Date",
                         num.rows.col = "Num.Rows",
                         compound.col = "Chemical.ID",
                         istd.col = "ISTD.Name",
                         sample.colname.col = "Sample.ColName",
                         type.colname.col = "Type.ColName",
                         peak.colname.col = "Peak.ColName",
                         istd.peak.colname.col = "ISTD.Peak.ColName",
                         conc.colname.col = "Conc.ColName",
                         analysis.param.colname.col = "Analysis.ColName",
                         INPUT.DIR = "C:/Users/stabatab/OneDrive - Environmental Protection Agency (EPA)/Profile/Desktop/ExpoCast_Projec/Project_Pred_Caco2_Clint_Fup/invitroTKstats/CyprotexTO1/modified_clint",
                         output.res = FALSE,catalog.out = FALSE)
```

```{r annotate_data}
# Set reasonable sig figs on retention time:

dc.hep=dc.hep1
dc.hep$Analysis.Params <- signif(as.numeric(dc.hep$Analysis.Params), 6)

# Get rid of NA notes:
dc.hep[is.na(dc.hep$Note),"Note"] <- ""

# Use invitroTKstats annotation of type for Crizer lab samples:
dc.hep <- subset(dc.hep,!is.na(Sample))

dc.hep$Type=0
dc.hep[regexpr("Blank",dc.hep$Sample)!=-1,"Type"] <- "Blank"
dc.hep[regexpr("__120_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"
dc.hep[regexpr("_120_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"

dc.hep[regexpr("__60_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"
dc.hep[regexpr("_60_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"

dc.hep[regexpr("__30_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"
dc.hep[regexpr("_30_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"

dc.hep[regexpr("__15_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"
dc.hep[regexpr("_15_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"


dc.hep[regexpr("__0",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"
dc.hep[regexpr("_0_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"

dc.hep[regexpr("_0_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"
dc.hep[regexpr("_0_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"

dc.hep[regexpr("__0_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"
dc.hep[regexpr("_0_",(dc.hep[,"Sample"]))!=-1, "Type"] <- "Cvst"

dc.hep[!(dc.hep$Type %in% c("Blank","Cvst")),"Type"]="Inactive"

#dc.hep[!grepl("Blank|120|60|30|15|__0_|_0_|__0",dc.hep[,"Sample"]),"Type"]<-"Inactive"
#dc.hep[grepl("HI___1|HI_1|HI___2|HI_2|HI_2|HI_3|HI___3",dc.hep[,"Sample"]), "Type"] <-"Inactive"


# Add time of sample:

dc.hep[,"Time"] <- NA
dc.hep[regexpr("Blank",dc.hep$Sample)!=-1,"Time"] <- 0
dc.hep[regexpr("__120_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 120/60
dc.hep[regexpr("_120_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 120/60

dc.hep[regexpr("__60_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 60/60
dc.hep[regexpr("_60_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 60/60

dc.hep[regexpr("__30_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 30/60
dc.hep[regexpr("_30_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 30/60

dc.hep[regexpr("__15_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 15/60
dc.hep[regexpr("_15_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 15/60

dc.hep[regexpr("__0",(dc.hep[,"Sample"]))!=-1,"Time"] <- 0/60
dc.hep[regexpr("_0_",(dc.hep[,"Sample"]))!=-1,"Time"] <- 0/60
dc.hep[regexpr("__0_",(dc.hep[,"Sample"]))!=-1, "Time"] <- 0/60
dc.hep[!grepl("__120_|_120_|__60_|_60_|__30_|_30_|__15_|_15_|__0|_0_|__0_|60|30|15|Blank|__0_|_0_|__0",dc.hep[,"Sample"]),"Time"]<-4

dc.hep[grepl("HI___1|HI_1|HI___2|HI_2|HI_2|HI_3|HI___3",dc.hep[,"Sample"]), "Time"] <-4

 
# 4 hourse for those dont have time and inactive type


# Figure out from sample name whether the hepatocytes were alive:
# Indicate whether hepatocytes have been inactivated:
dc.hep$Active.Hep <- NA


dc.hep <- subset(dc.hep,!is.na(dc.hep[,"Sample"]))


# Differentiate live hepatocytes from inactive:
dc.hep[dc.hep[,"Type"] %in% "Cvst", "Active.Hep"] <- 1
dc.hep[dc.hep[,"Type"] %in% "Inactive", "Active.Hep"] <- 0

```

# Identify Wetmore lab chemicals:
```{r wetmore_chems}
```

# Set the dilution facor for the various samples:
```{r dilution_factors}
dc.hep$Dilution.Factor <- 1

```


# Make sure the areas are numeric:
```{r numeric_peaks}
dc.hep$Peak.Area <- as.numeric(dc.hep$Peak.Area)
dc.hep$ISTD.Peak.Area <- as.numeric(dc.hep$ISTD.Peak.Area) 

dc.hep[,"Compound.Conc"] <- as.numeric(dc.hep[,"Compound.Conc"])
```


# Convert nM standard concs to uM:
```{r nmtoum}

dc.hep$Compound.Conc=0

dc.hep[grepl("Blank",dc.hep[,"Sample"]) != -1, "Compound.Conc"] <- 0
  


dc.hep[!dc.hep$Type %in% c("Blank") &regexpr("1 uM",dc.hep$Sample)!=-1,"Compound.Conc"] <-1 
dc.hep[!dc.hep$Type %in% c("Blank") &regexpr("1uM",dc.hep$Sample)!=-1,"Compound.Conc"] <-1
dc.hep[!dc.hep$Type %in% c("Blank") &regexpr("_1uM",dc.hep$Sample)!=-1,"Compound.Conc"] <-1
dc.hep[!dc.hep$Type %in% c("Blank") &regexpr("_1 uM",dc.hep$Sample)!=-1,"Compound.Conc"] <-1



dc.hep[!dc.hep$Type %in% c("Blank") &regexpr("10 uM",dc.hep$Sample)!=-1,"Compound.Conc"] <-10 
dc.hep[!dc.hep$Type %in% c("Blank") &regexpr("10uM",dc.hep$Sample)!=-1,"Compound.Conc"] <-10
dc.hep[!dc.hep$Type %in% c("Blank") &regexpr("_10uM",dc.hep$Sample)!=-1,"Compound.Conc"] <-10
dc.hep[!dc.hep$Type %in% c("Blank") &regexpr("_10 uM",dc.hep$Sample)!=-1,"Compound.Conc"] <-10

dc.hep$Compound.Conc[dc.hep$Type!="Blank" &
         !grepl("1 uM",dc.hep$Sample) &
         !grepl("1uM",dc.hep$Sample) &
         !grepl("_1uM",dc.hep$Sample)&
         !grepl("_1 uM",dc.hep$Sample) &
         grepl("1 uM",dc.hep$Level0.Sheet)] <-1

dc.hep$Compound.Conc[dc.hep$Type!="Blank" &
         !grepl("1 uM",dc.hep$Sample) &
         !grepl("1uM",dc.hep$Sample) &
         !grepl("_1uM",dc.hep$Sample)&
         !grepl("_1 uM",dc.hep$Sample) &
         grepl("1uM",dc.hep$Level0.Sheet)] <-1
dc.hep$Compound.Conc[dc.hep$Type!="Blank" &
         !grepl("1 uM",dc.hep$Sample) &
         !grepl("1uM",dc.hep$Sample) &
         !grepl("_1uM",dc.hep$Sample)&
         !grepl("_1 uM",dc.hep$Sample) &
         grepl("1 uM",dc.hep$Level0.Sheet)] <-1

dc.hep$Compound.Conc[dc.hep$Type!="Blank" &
         !grepl("1 uM",dc.hep$Sample) &
         !grepl("1uM",dc.hep$Sample) &
         !grepl("_1uM",dc.hep$Sample)&
         !grepl("_1 uM",dc.hep$Sample) &
         grepl("1uM",dc.hep$Level0.Sheet)] <-1



dc.hep$Compound.Conc[dc.hep$Type !="Blank" &
         !grepl("10 uM",dc.hep$Sample) &
         !grepl("10uM",dc.hep$Sample) &
         !grepl("_10uM",dc.hep$Sample)&
         !grepl("_10 uM",dc.hep$Sample) &
         grepl("10 uM",dc.hep$Level0.Sheet)] <-10

dc.hep$Compound.Conc[dc.hep$Type !="Blank" &
         !grepl("10 uM",dc.hep$Sample) &
         !grepl("01uM",dc.hep$Sample) &
         !grepl("_10uM",dc.hep$Sample)&
         !grepl("_10 uM",dc.hep$Sample) &
         grepl("10uM",dc.hep$Level0.Sheet)] <-10

library(dplyr)
library(stringr)

dc.hep <- dc.hep %>%
mutate(

Biological.Replicates = str_extract(Sample, "(?<=_0_)\\d"),


Biological.Replicates = ifelse(is.na(Biological.Replicates),
                             str_extract(Sample, "(?<=_)\\d(?=_|$)"),
                             Biological.Replicates),

Biological.Replicates = as.numeric(Biological.Replicates)
)

```

# Create level 1 file:
```{r level1}

level1 <- format_clint(dc.hep,
                       FILENAME="Cyprotex",
                       sample.col ="Sample",
                       date.col="Date",
                       compound.col="Compound",
                       dtxsid.col = "DTXSID",
                       lab.compound.col="Lab.Compound.ID",
                       type.col="Type",
                       dilution.col="Dilution.Factor",
                        istd.conc = 1,
                       area.col="Peak.Area",
                       istd.col= "ISTD.Peak.Area",
                       density = 0.5,
                       clint.assay.conc = 1,
                        analysis.parameters.col = "Analysis.Params",
                       note.col="Note",
                       test.conc.col="Compound.Conc",
                       time.col = "Time",
                       analysis.method = "MS",
                       cal = 1,
                      dilution = NULL,
                      istd.name = NULL,
                      istd.name.col = "ISTD.Name",
                      # istd.conc = NULL,
                      test.conc = NULL,
                      # clint.assay.conc = NULL,
                      biological.replicates = "Biological.Replicates",
                      technical.replicates =1,
                      analysis.instrument = "Instrument",
                      level0.file.col = "Level0.File",
                      level0.sheet.col = "Level0.Sheet",
                      output.res = TRUE,
                      save.bad.types = FALSE,
                      INPUT.DIR = NULL,
                      OUTPUT.DIR = NULL
)

save(level1, file= "C:/Users/stabatab/OneDrive - Environmental Protection Agency (EPA)/Profile/Desktop/ExpoCast_Projec/Project_Pred_Caco2_Clint_Fup/invitroTKstats/CyprotexTO1/out_Fup/Cyprotex-Clint-Level1.Rdata")

```
# Create level 2 file:
```{r create_level2file}


v=level1[grepl("Blank",level1$Lab.Sample.Name) & level1$Sample.Type=="Cvst",]


level2=level1
level2$Verified <- "Y"


write.table(level2,
            file="Cyprotex-Clint-Level2.tsv",
            sep="\t",
            row.names=F,
            quote=F)


```  

```{r plot_data}
for (this.id in unique(level2$DTXSID))
{
  this.subset <- subset(level2,DTXSID==this.id)
  try(plot(this.subset$Time,this.subset$Area,main=unique(this.subset$Compound.Name)))
}
```

```{r}
library(dplyr)

level2=level2 %>%
  filter(!is.nan(ISTD.Area), ISTD.Area !=0 ,!is.nan(Area), !is.na(Area),!is.nan(Time), !is.nan(Response),!is.na(Response))

write.table(level2,
            file="Cyprotex-Clint-Level2.tsv",
            sep="\t",
            row.names=F,
            quote=F)

level2=read.table("C:/Users/stabatab/OneDrive - Environmental Protection Agency (EPA)/Profile/Desktop/John-Project/Project_Pred_Clint_Fup_Dawson/invitroTKstats/CyprotexTO1/out_clint/Cyprotex-Clint-Level2.tsv",sep="\t",header = TRUE,stringsAsFactors = FALSE)

```
# Create level 1 file:
```{r point_estimates }

level3 <- calc_clint_point(FILENAME="Cyprotex")

level3=data.frame(level3)

library(openxlsx)

FilePath1=("C:\\Users\\stabatab\\OneDrive - Environmental Protection Agency (EPA)\\Profile\\Desktop\\John-Project\\Project_Pred_Clint_Fup_Dawson\\invitroTKstats\\CyprotexTO1\\out_clint\\162clintlevel3.xlsx")
write.xlsx(level3,file=FilePath1,rowNames=FALSE)



# 
# level3=level3 %>% filter(Compound.Name !="1-Octen-3-ol")
# 
# level3=level3[,colSums(is.na(level3))< nrow(level3)]

```

# repeat these bits in case a markov chain crashes and we need to restart:
```{r bayes_estimates}

library(invitroTKstats)
library(runjags)

setwd("C:/Users/stabatab/OneDrive - Environmental Protection Agency (EPA)/Profile/Desktop/John-Project/Project_Pred_Clint_Fup_Dawson/invitroTKstats/CyprotexTO1/out_clint")

level4 <- calc_clint(FILENAME="Cyprotex",
                     NUM.CORES=2,
                     JAGS.PATH="C:\\Users\\stabatab\\AppData\\Local\\Programs\\JAGS\\JAGS-4.3.1\\x64\\bin\\jags.bat")  


level4=read.table("Cyprotex-Clint-Level4.tsv",header= TRUE,sep="\t",stringsAsFactors = FALSE)



library(rjags)

model="model{
x~dnorm(0,1)
}"
jg=jags.model(textConnection(model),n.chains=1,n.adapt=1000)

``` 



